{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3616ecbb",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "A crucial property of CNPs is their flexibility at test time, as they can model\n",
    "a whole range of functions and narrow down their prediction as we condition on\n",
    "an increasing number of context observations. This behaviour is a result of the\n",
    "training regime of CNPs which is reflected in our datasets.\n",
    "\n",
    "![](https://bit.ly/2O2Lq8c)\n",
    "\n",
    "Rather than training using observations from a single function as it is often\n",
    "the case in machine learning (for example value functions in reinforcement\n",
    "learning) we will use a dataset that <h6>consists of many different functions that\n",
    "share some underlying characteristics.</h6> This is visualized in the figure above.\n",
    "The example on the left corresponds to a classic training regime: we have a\n",
    "single underlying ground truth function (eg. our value function for an agent) in\n",
    "grey and at each learning iteration we are provided with a handful of examples from this\n",
    "function that we have visualized in different colours for batches of different\n",
    "iterations. On the right we show an example of a dataset that could be used for\n",
    "training neural processes. <h6>Instead of a single function, it consists of a large number of functions of a function-class</h6> that we are interested in modeling. At each iteration we randomly choose one from the dataset and provide some observations from that function for training. For the next iteration we put that function back and\n",
    "pick a new one from our dataset and use this new function to select the training\n",
    "data. <h6>This type of dataset ensures that our model can't overfit to a single\n",
    "function but rather learns a distribution over functions.</h6> This idea of a\n",
    "hierarchical dataset also lies at the core of current meta-learning methods.\n",
    "Examples of such datasets could be:\n",
    "\n",
    "*  Functions describing the evolution of temperature over time in different cities \n",
    "of the world.\n",
    "*  A dataset of functions generated by a motion capture sensor of different humans\n",
    "    walking.\n",
    "*   As in this particular example differents functions generated by a Gaussian process (GP)\n",
    "    with a specific kernel.\n",
    "\n",
    "<h6>We have chosen GPs for the data generation of this example because they\n",
    "constitute an easy way of sampling smooth curves that share some underlying\n",
    "characteristic (in this case the kernel).</h6> Other than for data generation of this\n",
    "particular example neural processes do not make use of kernels or GPs as they\n",
    "are implemented as neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e8bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9918a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94d2407e",
   "metadata": {},
   "source": [
    "     \n",
    "          query: Array containing ((context_x, context_y), target_x) where:\n",
    "          \n",
    "          context_x: Array of shape batch_size x num_context x 1 \n",
    "          context_y: Array of shape batch_size x num_context x 1\n",
    "          \n",
    "          target_x: Array of shape batch_size x num_target x 1 \n",
    "          target_y: Array of shape batchsize x num_targets x 1.The ground truth y values of the target y.\n",
    "          \n",
    "          num_total_points: Number of target points.\n",
    "\n",
    "    Returns:\n",
    "      log_p: The log_probability of the target_y given the predicted\n",
    "      distribution.\n",
    "      mu: The mean of the predicted distribution.\n",
    "      sigma: The variance of the predicted distribution.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e7f0e1",
   "metadata": {},
   "source": [
    "## Data generator\n",
    "\n",
    "In the following section we provide the code for generating our training and\n",
    "testing sets using a GP to generate a dataset of functions. As we will explain\n",
    "later, CNPs use two subset of points at every iteration: one to serve as the\n",
    "context, and the other as targets. In practise we found that including the\n",
    "context points as targets together with some additional new points helped during\n",
    "training. Our data generator divides the generated data into these two groups\n",
    "and provides it in the correct format.<br>\n",
    "\n",
    "<h6>\n",
    "CNPRegressionDescription ::  iput of CNP<br>\n",
    "GPCurveReader :: data sampled from GP at each iteration \n",
    "    </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b4fc2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user0</td>\n",
       "      <td>0</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user1</td>\n",
       "      <td>1</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user2</td>\n",
       "      <td>4</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user3</td>\n",
       "      <td>9</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user4</td>\n",
       "      <td>16</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user5</td>\n",
       "      <td>25</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user6</td>\n",
       "      <td>36</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>user7</td>\n",
       "      <td>49</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user8</td>\n",
       "      <td>64</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user9</td>\n",
       "      <td>81</td>\n",
       "      <td>there is sth in the middle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age                        text\n",
       "0  user0    0  there is sth in the middle\n",
       "1  user1    1  there is sth in the middle\n",
       "2  user2    4  there is sth in the middle\n",
       "3  user3    9  there is sth in the middle\n",
       "4  user4   16  there is sth in the middle\n",
       "5  user5   25  there is sth in the middle\n",
       "6  user6   36  there is sth in the middle\n",
       "7  user7   49  there is sth in the middle\n",
       "8  user8   64  there is sth in the middle\n",
       "9  user9   81  there is sth in the middle"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"name\" , \"age\" ,\"text\"])\n",
    "for i in range(10):\n",
    "    df.loc[i] = [f\"user{i}\" , i**2 , \"there is sth in the middle\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a18f7d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76564b98",
   "metadata": {},
   "source": [
    "### concat note \n",
    "#### [3,10,5]\n",
    "####  [3,10,5]\n",
    "<br>\n",
    "axis= 0 means [6,10,5] <br>\n",
    "axis= 1 means [3,20,5] <br>\n",
    "axis= 2 means [3,10,10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bd5cd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 100, 2]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 10 \n",
    "tensor = tf.zeros([bs,2,5])\n",
    "context_x = tf.zeros([bs , 100 , 1])\n",
    "context_y = tf.zeros([bs , 100 , 1])\n",
    "encoder_input = tf.concat([context_x, context_y], axis=-1)\n",
    "encoder_input.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420a63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70fd4e24",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "The encoder **e** is shared between all the context points and consists of an\n",
    "MLP with a handful of layers. For this experiment four layers are enough [128,128,128,128] </br>, but we\n",
    "can still change the number and size of the layers when we build the graph later\n",
    "on via the variable **`encoder_output_sizes`**. Each of the context pairs **(x,\n",
    "y)<sub>i</sub>** results in an individual representation **r<sub>i</sub>** after\n",
    "encoding. These representations are then combined across context points to form\n",
    "a single representation **r** using the aggregator **a**.\n",
    "\n",
    "In this implementation we have included the aggregator **a** in the encoder as\n",
    "we are only taking the mean across all points. The representation **r** produced\n",
    "by the aggregator contains the information about the underlying unknown function\n",
    "**f** that is provided by all the context points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269ecb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicEncoder(object):\n",
    "  \"\"\"The Encoder.\"\"\"\n",
    "\n",
    "  def __init__(self, output_sizes):\n",
    "    \"\"\"CNP encoder.\"\"\"\n",
    "    self._output_sizes = output_sizes\n",
    "\n",
    "    \n",
    "  def __call__(self, context_x, context_y, num_context_points):\n",
    "\n",
    "    # Concatenate x and y along the filter axes\n",
    "    encoder_input = tf.concat([context_x, context_y], axis=-1)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Get the shapes of the input and reshape to parallelise across observations\n",
    "    batch_size, _, filter_size = encoder_input.shape.as_list()\n",
    "    hidden = tf.reshape(encoder_input, (batch_size * num_context_points, -1))\n",
    "    hidden.set_shape((None, filter_size))\n",
    "\n",
    "    # Pass through MLP\n",
    "    # , reuse=tf.compact.v1.AUTO_REUSE\n",
    "    with tf.compat.v1.variable_scope(\"encoder\"):\n",
    "      for i, size in enumerate(self._output_sizes[:-1]):\n",
    "        hidden = tf.nn.relu(\n",
    "            tf.compat.v1.layers.dense(hidden, size, name=\"Encoder_layer_{}\".format(i)))\n",
    "\n",
    "      # Last layer without a ReLu\n",
    "      hidden = tf.compat.v1.layers.dense(\n",
    "          hidden, self._output_sizes[-1], name=\"Encoder_layer_{}\".format(i + 1))\n",
    "\n",
    "    # Bring back into original shape\n",
    "    hidden = tf.reshape(hidden, (batch_size, num_context_points, size))\n",
    "\n",
    "    # Aggregator: take the mean over all points\n",
    "    representation = tf.reduce_mean(hidden, axis=1)\n",
    "\n",
    "    return representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe6af0",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "Once we have obtained our representation **r** we concatenate it with each of\n",
    "the targets **x<sub>t</sub>** and pass it through the decoder **d**. As with the\n",
    "encoder **e**, the decoder **d** is shared between all the target points and\n",
    "consists of a small MLP with layer sizes defined in **`decoder_output_sizes`**.<br>\n",
    "[128,128,2] <br>\n",
    "The decoder outputs a mean **&mu;<sub>t</sub>** and a variance\n",
    "**&sigma;<sub>t</sub>** for each of the targets **x<sub>t</sub>**. To train our\n",
    "CNP we use the log likelihood of the ground truth value **y<sub>t</sub>** under\n",
    "a Gaussian parametrized by these predicted **&mu;<sub>t</sub>** and\n",
    "**&sigma;<sub>t</sub>**.\n",
    "\n",
    "In this implementation we clip the variance **&sigma;<sub>t</sub>** at 0.1 to\n",
    "avoid collapsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff1d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicDecoder(object):\n",
    "  \"\"\"The Decoder.\"\"\"\n",
    "\n",
    "  def __init__(self, output_sizes):\n",
    "    \"\"\"CNP decoder.\n",
    "\n",
    "    Args:\n",
    "      output_sizes: An iterable containing the output sizes of the decoder MLP \n",
    "          as defined in `basic.Linear`.\n",
    "    \"\"\"\n",
    "    self._output_sizes = output_sizes\n",
    "\n",
    "  def __call__(self, representation, target_x, num_total_points):\n",
    "    \"\"\"Decodes the individual targets.\n",
    "\n",
    "    Args:\n",
    "      representation: The encoded representation of the context\n",
    "      target_x: The x locations for the target query\n",
    "      num_total_points: The number of target points.\n",
    "\n",
    "    Returns:\n",
    "      dist: A multivariate Gaussian over the target points.\n",
    "      mu: The mean of the multivariate Gaussian.\n",
    "      sigma: The standard deviation of the multivariate Gaussian.\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate the representation and the target_x\n",
    "    representation = tf.tile(\n",
    "        tf.expand_dims(representation, axis=1), [1, num_total_points, 1])\n",
    "    input = tf.concat([representation, target_x], axis=-1)\n",
    "\n",
    "    # Get the shapes of the input and reshape to parallelise across observations\n",
    "    batch_size, _, filter_size = input.shape.as_list()\n",
    "    hidden = tf.reshape(input, (batch_size * num_total_points, -1))\n",
    "    hidden.set_shape((None, filter_size))\n",
    "\n",
    "    # Pass through MLP\n",
    "    with tf.compat.v1.variable_scope(\"decoder\"):\n",
    "      for i, size in enumerate(self._output_sizes[:-1]):\n",
    "        hidden = tf.nn.relu(\n",
    "            tf.compat.v1.layers.dense(hidden, size, name=\"Decoder_layer_{}\".format(i)))\n",
    "\n",
    "      # Last layer without a ReLu\n",
    "      hidden = tf.compat.v1.layers.dense(\n",
    "          hidden, self._output_sizes[-1], name=\"Decoder_layer_{}\".format(i + 1))\n",
    "\n",
    "    # Bring back into original shape\n",
    "    hidden = tf.reshape(hidden, (batch_size, num_total_points, -1))\n",
    "\n",
    "    # Get the mean an the variance\n",
    "    mu, log_sigma = tf.split(hidden, 2, axis=-1)\n",
    "\n",
    "    # Bound the variance\n",
    "    sigma = 0.1 + 0.9 * tf.nn.softplus(log_sigma)\n",
    "\n",
    "    # Get the distribution\n",
    "#     dist = tf.contrib.distributions.MultivariateNormalDiag(\n",
    "#         loc=mu, scale_diag=sigma)\n",
    "#     dist = tf.compat.v1.distributions.MultivariateNormalDiag(\n",
    "#         loc=mu, scale_diag=sigma)\n",
    "    dist = tfp.distributions.MultivariateNormalDiag(\n",
    "        loc=mu, scale_diag=sigma)\n",
    "    \n",
    "\n",
    "    return dist, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2d4eb",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Now that the main building blocks (encoder, aggregator and decoder) of the CNP\n",
    "are defined we can put everything together into one model. Fundamentally this\n",
    "model only needs to include two main methods: 1. A method that returns the log\n",
    "likelihood of the targets' ground truth values under the predicted\n",
    "distribution.This method will be called during training as our loss function. 2.\n",
    "Another method that returns the predicted mean and variance at the target\n",
    "locations in order to evaluate or query the CNP at test time. This second method\n",
    "needs to be defined separately as, unlike the method above, it should not depend\n",
    "on the ground truth target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a6ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicModel(object):\n",
    "  \"\"\"The CNP model.\"\"\"\n",
    "\n",
    "  def __init__(self, encoder_output_sizes, decoder_output_sizes):\n",
    "   \n",
    "    self._encoder = DeterministicEncoder(encoder_output_sizes)\n",
    "    self._decoder = DeterministicDecoder(decoder_output_sizes)\n",
    "\n",
    "  def __call__(self, query, num_total_points, num_contexts, target_y=None):\n",
    "\n",
    "    (context_x, context_y), target_x = query\n",
    "\n",
    "    # Pass query through the encoder and the decoder\n",
    "    representation = self._encoder(context_x, context_y, num_contexts)\n",
    "    dist, mu, sigma = self._decoder(representation, target_x, num_total_points)\n",
    "\n",
    "    # If we want to calculate the log_prob for training we will make use of the\n",
    "    # target_y. At test time the target_y is not available so we return None\n",
    "    if target_y is not None:\n",
    "      log_p = dist.log_prob(target_y)\n",
    "    else:\n",
    "      log_p = None\n",
    "\n",
    "    return log_p, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c414a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>4129</td>\n",
       "      <td>5/30/2023</td>\n",
       "      <td>177.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>4130</td>\n",
       "      <td>5/31/2023</td>\n",
       "      <td>177.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>4131</td>\n",
       "      <td>6/1/2023</td>\n",
       "      <td>180.089996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>4132</td>\n",
       "      <td>6/2/2023</td>\n",
       "      <td>180.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>4133</td>\n",
       "      <td>6/5/2023</td>\n",
       "      <td>179.580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>4134</td>\n",
       "      <td>6/6/2023</td>\n",
       "      <td>179.210007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>4135</td>\n",
       "      <td>6/7/2023</td>\n",
       "      <td>177.820007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>4136</td>\n",
       "      <td>6/8/2023</td>\n",
       "      <td>180.570007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>4137</td>\n",
       "      <td>6/9/2023</td>\n",
       "      <td>180.960007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>4138</td>\n",
       "      <td>6/12/2023</td>\n",
       "      <td>183.789993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       Date       Close\n",
       "4129        4129  5/30/2023  177.300003\n",
       "4130        4130  5/31/2023  177.250000\n",
       "4131        4131   6/1/2023  180.089996\n",
       "4132        4132   6/2/2023  180.949997\n",
       "4133        4133   6/5/2023  179.580002\n",
       "4134        4134   6/6/2023  179.210007\n",
       "4135        4135   6/7/2023  177.820007\n",
       "4136        4136   6/8/2023  180.570007\n",
       "4137        4137   6/9/2023  180.960007\n",
       "4138        4138  6/12/2023  183.789993"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"AAPL_price.csv\")\n",
    "dataset.tail(10)\n",
    "# data_train = 0 \n",
    "# data_test =  0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c696ed",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9c6cca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m decoder_output_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m DeterministicModel(encoder_output_sizes, decoder_output_sizes)\n\u001b[1;32m----> 7\u001b[0m log_prob, _, _ \u001b[38;5;241m=\u001b[39m model(\u001b[43mdata_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m, data_train\u001b[38;5;241m.\u001b[39mnum_total_points,\n\u001b[0;32m      8\u001b[0m                        data_train\u001b[38;5;241m.\u001b[39mnum_context_points, data_train\u001b[38;5;241m.\u001b[39mtarget_y)\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtf\u001b[38;5;241m.\u001b[39mreduce_mean(log_prob)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# _, mu, sigma = model(data_test.query, data_test.num_total_points,\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#                      data_test.num_context_points)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# train_step = optimizer.minimize(loss)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# init = tf.initialize_all_variables()\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "encoder_output_sizes = [128, 128, 128, 128]\n",
    "decoder_output_sizes = [128, 128, 2]\n",
    "model = DeterministicModel(encoder_output_sizes, decoder_output_sizes)\n",
    "\n",
    "\n",
    "\n",
    "log_prob, _, _ = model(data_train.query, data_train.num_total_points,\n",
    "                       data_train.num_context_points, data_train.target_y)\n",
    "loss = -tf.reduce_mean(log_prob)\n",
    "\n",
    "\n",
    "\n",
    "# _, mu, sigma = model(data_test.query, data_test.num_total_points,\n",
    "#                      data_test.num_context_points)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Set up the optimizer and train step\n",
    "# optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "# train_step = optimizer.minimize(loss)\n",
    "# init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6752dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "\n",
    "  for it in range(TRAINING_ITERATIONS):\n",
    "    sess.run([train_step])\n",
    "\n",
    "    # Plot the predictions in `PLOT_AFTER` intervals\n",
    "    if it % PLOT_AFTER == 0:\n",
    "      loss_value, pred_y, var, target_y, whole_query = sess.run(\n",
    "          [loss, mu, sigma, data_test.target_y, data_test.query])\n",
    "\n",
    "      (context_x, context_y), target_x = whole_query\n",
    "      print('Iteration: {}, loss: {}'.format(it, loss_value))\n",
    "\n",
    "      # Plot the prediction and the context\n",
    "      plot_functions(target_x, target_y, context_x, context_y, pred_y, var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
